{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"'2.1.0'"},"metadata":{}}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\n# import matplotlib\n# import matplotlib.pyplot as plt\n# plt.style.use(\"ggplot\")\n\n# # matplotlib.use('agg')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport cv2\nprint(\"Imported Tensorflow\")","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Imported Tensorflow\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"'2.1.0'"},"metadata":{}}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Set some parameters\nIMG_WIDTH = 512\nIMG_HEIGHT = 512\nIMG_CHANNELS = 1\nTRAIN_PATH = '../input/lungsenhanced/LungsEnhanced/'\nTEST_PATH = '../input/unetlungsdata/data/test/'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 2040\nrandom.seed = seed\nnp.random.seed = seed\n\nprint(\"Imported all the dependencies\")","execution_count":4,"outputs":[{"output_type":"stream","text":"Imported all the dependencies\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(os.listdir(\"../input/weights/best.hdf5\"))","execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/weights/best.hdf5'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-089e45e2e70e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/weights/best.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/weights/best.hdf5'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\nempty = []\nfor train_id in train_ids:\n    if os.path.exists(TRAIN_PATH+train_id+'/images'):\n        continue\n    else:\n        empty.append(train_id)\ntrain_ids = list(set(train_ids) - set(empty))\nprint(len(train_ids))\ntrain_ids_1 = train_ids[:len(train_ids)//2]\ntrain_ids_2 = train_ids[len(train_ids)//2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Get train and test IDs\n#train_ids = next(os.walk(TRAIN_PATH))[1]\n\n# Get and resize train images and masks\nX_train = np.zeros((len(train_ids_2), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids_2), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\nprint(\"X_train\",X_train.shape)\nprint(\"Y_train\",Y_train.shape)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfor n, id_ in tqdm(enumerate(train_ids_2), total=len(train_ids_2)):\n\tpath = TRAIN_PATH + id_\n\timg = imread(path + '/images/' + id_ + '.png')\n\timg = resize(img, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n\tX_train[n] = img\n\tmask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\tfor mask_file in next(os.walk(path + '/masks/'))[2]:\n\t\tmask_ = imread(path + '/masks/' + mask_file)\n\t\tmask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',preserve_range=True), axis=-1)\n\t\tmask = np.maximum(mask, mask_)\n\tY_train[n] = mask\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Check if training data looks all right\nix = random.randint(0, len(train_ids_1))\n\nimshow(np.squeeze(X_train[ix]))\nplt.show();\nplt.savefig('img.png')\n\nimshow(np.squeeze(Y_train[ix]))\nplt.show();\nplt.savefig('mask.png')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.dtypes.cast(y_pred > t,tf.int32)\n        score, up_opt = tf.metrics.MeanIoU(num_classes=2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef iou_coef(y_true, y_pred, smooth=1):\n  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2])\n  union = K.sum(y_true,[1,2])+K.sum(y_pred,[1,2])-intersection\n  iou = K.mean((intersection ) / (union), axis=0)\n  return iou","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2])\n    union = K.sum(y_true, axis=[1,2]) + K.sum(y_pred, axis=[1,2])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\ndef dice_p_bce(in_gt, in_pred):\n    return 0.0*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\ndef true_positive_rate(y_true, y_pred):\n    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n#seg_model.load_weights('../input/weights/seg_model_weights.best.hdf5')\n#seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = X_train[:15000]\nY_train = Y_train[:15000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Activation, Conv2D, MaxPool2D, UpSampling2D, Dropout, concatenate, BatchNormalization, Cropping2D, ZeroPadding2D, SpatialDropout2D\nfrom keras.layers import Conv2DTranspose, Dropout, GaussianNoise\nfrom keras.models import Model\nfrom keras import backend as K\n\ndef up_scale(in_layer):\n    filt_count = in_layer._keras_shape[-1]\n    return Conv2DTranspose(filt_count, kernel_size = (2,2), strides = (2,2), padding = 'same')(in_layer)\ndef up_scale_fancy(in_layer):\n    return UpSampling2D(size=(2,2))(in_layer)\n\ninput_layer = Input(shape=X_train.shape[1:])\nsp_layer = GaussianNoise(0.1)(input_layer)\nbn_layer = BatchNormalization()(sp_layer)\nc1 = Conv2D(filters=8, kernel_size=(5,5), activation='relu', padding='same')(bn_layer)\nl = MaxPool2D(strides=(2,2))(c1)\nc2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c2)\nc3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\n\nl = MaxPool2D(strides=(2,2))(c3)\nc4 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\n\nl = SpatialDropout2D(0.25)(c4)\ndil_layers = [l]\nfor i in [2, 4, 6, 8, 12, 18, 24]:\n    dil_layers += [Conv2D(16,\n                          kernel_size = (3, 3), \n                          dilation_rate = (i, i), \n                          padding = 'same',\n                         activation = 'relu')(l)]\nl = concatenate(dil_layers)\n\n\nl = SpatialDropout2D(0.2)(concatenate([up_scale(l), c3], axis=-1))\nl = Conv2D(filters=128, kernel_size=(2,2), activation='linear', padding='same')(l)\nl = BatchNormalization()(l)\nl = Activation('relu')(l)\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (l)\nl = Conv2D(filters=96, kernel_size=(2,2), activation='relu', padding='same')(u9)\nl = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\nu10 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (l)\nl = Conv2D(filters=16, kernel_size=(2,2), activation='linear', padding='same')(u10)\n\nl = Cropping2D((4,4))(l)\nl = BatchNormalization()(l)\nl = Activation('relu')(l)\n\nl = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(l)\noutput_layer = ZeroPadding2D((4,4))(l)\n\nseg_model = Model(input_layer, output_layer)\nseg_model.load_weights(\"../input/weights3/best.hdf5\")\nseg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[tf.metrics.MeanIoU(num_classes=2), dice_coef, 'binary_accuracy', true_positive_rate])\nseg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2])\n    union = K.sum(y_true, axis=[1,2]) + K.sum(y_pred, axis=[1,2])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\ndef dice_p_bce(in_gt, in_pred):\n    return 0.0*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\ndef true_positive_rate(y_true, y_pred):\n    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\nseg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[tf.metrics.MeanIoU(num_classes=2),dice_coef, 'binary_accuracy', true_positive_rate])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('seg_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"mean_io_u_\", \n                      mode=\"max\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndg_args = dict(featurewise_center = False, \n                  samplewise_center = False,\n                  rotation_range = 7.5, \n                  width_shift_range = 0.02, \n                  height_shift_range = 0.02, \n                  shear_range = 0.01,\n                  zoom_range = [0.9, 1.25],  \n                  brightness_range = [0.9, 1.1],\n                  horizontal_flip = False, \n                  vertical_flip = False,\n                  fill_mode = 'nearest',\n                   data_format = 'channels_last')\n\nimage_gen = ImageDataGenerator(**dg_args)\ndg_args.pop('brightness_range')\nlabel_gen = ImageDataGenerator(**dg_args)\n# def train_gen(batch_size = 16, seed = None):\n#     np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n#     while True:\n#         seed = np.random.choice(range(9999))\n#         # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n#         batch_count = X_train.shape[0]//batch_size\n#         batch_id = np.random.permutation(range(0, X_train.shape[0]-batch_size, batch_size))\n#         for c_idx in batch_id:\n#             g_x = image_gen.flow(X_train[c_idx:(c_idx+batch_size)], batch_size = batch_size, seed = seed, shuffle=True)\n#             g_y = label_gen.flow(Y_train[c_idx:(c_idx+batch_size)], batch_size = batch_size, seed = seed, shuffle=True)\n#             yield next(g_x)/255.0, next(g_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nloss_history = [seg_model.fit(X_train, Y_train, validation_split=0.1, batch_size=32, epochs=50,callbacks=callbacks_list)]\n#                 fit_generator(image_gen.flow(X_train, Y_train, batch_size=batch_size),\n#                              steps_per_epoch=X_train.shape[0]//batch_size, \n#                              epochs=40, \n#                              validation_split=0.1,\n#                              callbacks=callbacks_list,\n#                             workers=2)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_model.save('../working/bestweights.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(4,3, figsize = (20, 20))\n[c_ax.axis('off') for c_ax in m_axs.flatten()]\nfor idx, (ax1, ax2, ax3) in enumerate(m_axs):\n    ix = X_train[idx:idx+1]\n    iy = Y_train[idx:idx+idx+1]\n    p_image = seg_model.predict(ix)\n    ax1.imshow(ix[0,:,:,0], cmap = 'gray')\n    ax1.set_title('Input Image')\n    ax2.imshow(iy[0,:,:,0], vmin = 0, vmax = 1, cmap = 'bone_r' )\n    ax2.set_title('Ground Truth')\n    ax3.imshow(p_image[0,:,:,0], vmin = 0, vmax = 1, cmap = 'viridis' )\n    ax3.set_title('Prediction')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# # Build U-Net model\n# import keras\n# inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n# s = Lambda(lambda x: x / 255) (inputs)\n\n# c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n# c1 = Dropout(0.1) (c1)\n# c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n# p1 = MaxPooling2D((2, 2)) (c1)\n\n# c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n# c2 = Dropout(0.1) (c2)\n# c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n# p2 = MaxPooling2D((2, 2)) (c2)\n\n# c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n# c3 = Dropout(0.2) (c3)\n# c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n# p3 = MaxPooling2D((2, 2)) (c3)\n\n# c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n# c4 = Dropout(0.2) (c4)\n# c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n# p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n# c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n# c5 = Dropout(0.3) (c5)\n# c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n# u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n# u6 = concatenate([u6, c4])\n# c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n# c6 = Dropout(0.2) (c6)\n# c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n# u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n# u7 = concatenate([u7, c3])\n# c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n# c7 = Dropout(0.2) (c7)\n# c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n# u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n# u8 = concatenate([u8, c2])\n# c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n# c8 = Dropout(0.1) (c8)\n# c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n# u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n# u9 = concatenate([u9, c1], axis=3)\n# c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n# c9 = Dropout(0.1) (c9)\n# c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n# outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n# model = Model(inputs=[inputs], outputs=[outputs])\n# model.load_weights('../input/bestweights/seg_model_weights.best.hdf5')\n# model.compile(optimizer='adam', loss=[iou_coef], metrics=[tf.metrics.MeanIoU(num_classes=2), dice_coef, 'binary_accuracy', true_positive_rate])\n# model.summary()\n# print(\"The model is defined\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Fit model\nearlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=30, epochs=5)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\n\npreds_train_t = (preds_train > 0.1).astype(np.uint8)\npreds_val_t = (preds_val > 0.1).astype(np.uint8)\npreds_test_t = (preds_test > 0.1).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in range(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\n\n# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train_t))\nimshow(np.squeeze(X_train[ix]))\nplt.show();\nplt.savefig('img.png')\nimshow(np.squeeze(Y_train[ix]))\nplt.show();\nplt.savefig('gt.png')\nimshow(np.squeeze(preds_train[ix]))\nplt.show();\nplt.savefig('predict.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_train_t[ix].shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from zf_unet_224_model import ZF_UNET_224, dice_coef_loss, dice_coef\nfrom keras.optimizers import Adam\n\nmodel = ZF_UNET_224(weights='generator')\noptim = Adam()\nmodel.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])\n\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=30, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}