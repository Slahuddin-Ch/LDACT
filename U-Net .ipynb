{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import print_function\nimport keras\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten, Activation\nfrom keras.layers.convolutional import Conv2D\nfrom keras.optimizers import Adam\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.utils import to_categorical\nfrom scipy.interpolate import griddata\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ntestdata = pd.read_csv('../input/Test.csv')\ntestdata = testdata.iloc[:,368:1392]\ntraindata = pd.read_csv('../input/Train.csv')\nlabels = traindata.iloc[:,-1]\ntraindata200 = traindata.iloc[:,0:200]\ntraindata = traindata.iloc[:,368:1392]\n\n#traindata = traindata.interpolate(method ='cubic',axis=1)\n#traindata['labels'] = pd.DataFrame(labels)\n#traindata = traindata.iloc[:,368:1392]\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata200.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=0\ndif = 0\nfor i in range(0,200):\n    for j in range(0,1024):\n        check = True\n        for k in range(1,1000):\n            if  ~np.isnan(traindata.iloc[k,j]) and ~np.isnan(traindata200.iloc[k,i]):\n                if round(traindata.iloc[k,j]) > round(traindata200.iloc[k,i]) + 3 or round(traindata.iloc[k,j]) < round(traindata200.iloc[k,i]) - 3:\n                    check = False\n                    break\n\n        if check == True:\n            traindata.iloc[:,j] = traindata200.iloc[:,i]\n            break\ntraindata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_to_lstm(df):\n    X = df.values\n    \n    return np.reshape(X, (X.shape[0], 32, 32))\n\n\ntrain_new = format_to_lstm(traindata)\nprint(train_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndata_filled = []\nfor i in range(train_new.shape[0]):\n    x = train_new[i,:,:]\n\n    xx = np.arange(32)\n    yy = np.arange(32)\n    coords = np.array(np.meshgrid(xx,yy)).T.reshape(-1,2)\n    mask = ~np.isnan(x)\n    points = np.argwhere(mask)\n    values = x[~np.isnan(x)]\n\n    grid = griddata((points[:,0],points[:,1]), values, coords, method='cubic',fill_value=255)\n    data_filled.append(grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_ready = data_filled\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_ready = np.array(data_ready)\nprint(data_ready.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_new = format_to_lstm(testdata)\ntest_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled = []\n\nfor i in range(test_new.shape[0]):\n    x = test_new[i,:,:]\n\n    xx = np.arange(32)\n    yy = np.arange(32)\n    coords = np.array(np.meshgrid(xx,yy)).T.reshape(-1,2)\n    mask = ~np.isnan(x)\n    points = np.argwhere(mask)\n    values = x[~np.isnan(x)]\n\n    grid = griddata((points[:,0],points[:,1]), values, coords, method='cubic',fill_value=255)\n    test_filled.append(grid)\ntest_ready = np.array(test_filled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_ready.reshape(test_ready.shape[0],32,32,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(data_ready)\nX_train = X_train.reshape(X_train.shape[0],32,32,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_classifier = Sequential()\n\n# 1st conv. layer\ncnn_classifier.add(Conv2D(32, (3, 3), input_shape = (32, 32, 1), activation = 'relu'))\ncnn_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# 2nd conv. layer\ncnn_classifier.add(Conv2D(32, (3, 3), activation = 'relu')) \ncnn_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# 3nd conv. layer\ncnn_classifier.add(Conv2D(64, (3, 3), activation = 'relu')) \ncnn_classifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Flattening\ncnn_classifier.add(Flatten())\n\n# Full connection\ncnn_classifier.add(Dense(units = 64, activation = 'relu'))\ncnn_classifier.add(Dropout(0.5)) \ncnn_classifier.add(Dense(units = 1, activation = 'sigmoid'))\n\ncnn_classifier.compile(optimizer = 'adam', \n                       loss = 'binary_crossentropy', \n                       metrics = ['accuracy'])\n \ncnn_classifier.fit(X_train, labels, batch_size=256, epochs=50)    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nreslt = cnn_classifier.predict_classes(X_test)\nreslt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"id = np.arange(0,9700)\nsubmission = pd.DataFrame({'id':id,'labels':reslt})\nsubmission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"filename = 'PredictionsF.csv'\n\nsubmission.to_csv(filename,index=False)\n\n#print('Saved file: ' + filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# import numpy as np\n\n# from keras.callbacks import EarlyStopping\n# from keras.datasets import cifar10\n# from keras.models import Sequential\n# from keras.layers.core import Dense, Dropout, Flatten\n# from keras.layers.convolutional import Conv2D\n# from keras.optimizers import Adam\n# from keras.layers.pooling import MaxPooling2D\n# from keras.utils import to_categorical\n\n# # For reproducibility\n# np.random.seed(1000)\n\n# if __name__ == '__main__':\n#     # Load the dataset\n#     X_train = np.array(data_ready)\n#     X_train = X_train.reshape(X_train.shape[0],32,32,1)\n#     Y_train = labels\n\n#     # Create the model\n#     model = Sequential()\n\n#     model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 1)))\n#     model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2, 2)))\n#     model.add(Dropout(0.25))\n    \n\n#     model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2, 2)))\n#     model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2, 2)))\n#     model.add(Dropout(0.25))\n\n#     model.add(Flatten())\n#     model.add(Dense(1024, activation='relu'))\n#     model.add(Dropout(0.5))\n#     model.add(Dense(10, activation='softmax'))\n\n#     # Compile the model\n#     model.compile(loss='categorical_crossentropy',\n#                   optimizer=Adam(lr=0.0001, decay=1e-6),\n#                   metrics=['accuracy'])\n\n#     # Train the model\n#     model.fit(X_train / 255.0, to_categorical(Y_train),batch_size=256,shuffle=True,epochs=100,callbacks=[EarlyStopping(min_delta=0.001, patience=3)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#print(os.listdir(\"../output\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# grid = np.reshape(grid, (32, 32))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# x= traindata.iloc[233]\n# #x = x.fillna(x.median())\n# x = x.values\n\n# x= np.reshape(x,(32,32))\n\n\n# xx = np.arange(32)\n# yy = np.arange(32)\n# coords = np.array(np.meshgrid(xx,yy)).T.reshape(-1,2)\n# mask = ~np.isnan(x)\n# points = np.argwhere(mask)\n# values = x[~np.isnan(x)]\n\n# grid = griddata((points[:,0],points[:,1]), values, coords, method='cubic',fill_value=255)\n# grid= np.reshape(grid,(32,32))\n\n# import matplotlib.pyplot as plt\n# plt.imshow(grid, cmap='gray')\n# plt.title('Cubic')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n# X = x\n# plt.imshow(X, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#traindata['labels'] = pd.DataFrame(labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# td1 = traindata.loc[traindata['labels'] == 1.0]\n# td2 = traindata.loc[traindata['labels'] == 2.0]\n# td3 = traindata.loc[traindata['labels'] == 3.0]\n# td4 = traindata.loc[traindata['labels'] == 4.0]\n# td5 = traindata.loc[traindata['labels'] == 5.0]\n# td6 = traindata.loc[traindata['labels'] == 6.0]\n# td7 = traindata.loc[traindata['labels'] == 7.0]\n# td8 = traindata.loc[traindata['labels'] == 8.0]\n# td9 = traindata.loc[traindata['labels'] == 9.0] \n# td0 = traindata.loc[traindata['labels'] == 0.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# df0 = (td0.std(axis=1))*3 - td0.mean(axis=1) \n# df0 = df0.loc[df0 < 0]\n# df1 = (td1.std(axis=1))*3 - td1.mean(axis=1)\n# df1 = df1.loc[df1 < 0]\n# df2 = (td2.std(axis=1))*3 - td2.mean(axis=1)\n# df2 = df2.loc[df2 < 0]\n# df3 = (td3.std(axis=1))*3 - td3.mean(axis=1)\n# df3 = df3.loc[df3 < 0]\n# df4 = (td4.std(axis=1))*3 - td4.mean(axis=1)\n# df4 = df4.loc[df4 < 0]\n# df5 = (td5.std(axis=1))*3 - td5.mean(axis=1)\n# df5 = df5.loc[df5 < 0]\n# df6 = (td6.std(axis=1))*3 - td6.mean(axis=1)\n# df6 = df6.loc[df6 < 0]\n# df7 = (td7.std(axis=1))*3 - td7.mean(axis=1)\n# df7 = df7.loc[df7 < 0]\n# df8 = (td8.std(axis=1))*3 - td8.mean(axis=1)\n# df8 = df8.loc[df8 < 0]\n# df9 = (td9.std(axis=1))*3 - td9.mean(axis=1)\n# df9 = df9.loc[df9 < 0]\n# outliers = pd.concat([df0,df1,df2,df3,df4,df5,df6,df7,df8,df9])\n# traindata = traindata.iloc[traindata.index[np.isin(traindata.index,outliers.index,invert=True)]]\n# outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from __future__ import print_function\n# import keras\n# from keras.datasets import cifar10\n# from keras.preprocessing.image import ImageDataGenerator\n# from keras.models import Sequential\n# from keras.layers import Dense, Dropout, Activation, Flatten\n# from keras.layers import Conv2D, MaxPooling2D\n# import os\n\n# batch_size = 256\n# num_classes = 10\n# epochs = 100\n# data_augmentation = True\n# save_dir = os.path.join(os.getcwd(), 'saved_models')\n# model_name = 'keras_cifar10_trained_model.h5'\n\n# # The data, split between train and test sets:\n# x_train = np.array(data_ready)\n# x_train = x_train.reshape(x_train.shape[0],32,32,1)\n# print('x_train shape:', x_train.shape)\n# print(x_train.shape[0], 'train samples')\n\n\n# # Convert class vectors to binary class matrices.\n# y_train = keras.utils.to_categorical(labels, 10)\n\n# #y_test = keras.utils.to_categorical(y_test, num_classes)\n\n# model = Sequential()\n# model.add(Conv2D(32, (3, 3), padding='same',input_shape=(32,32,1)))\n# model.add(Activation('relu'))\n# model.add(Conv2D(32, (3, 3)))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Conv2D(64, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(Conv2D(64, (3, 3)))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Flatten())\n# model.add(Dense(512))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(num_classes))\n# model.add(Activation('softmax'))\n\n# # initiate RMSprop optimizer\n# opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n\n# # Let's train the model using RMSprop\n# model.compile(loss='categorical_crossentropy',\n#               optimizer=opt,\n#               metrics=['accuracy'])\n\n# x_train = x_train.astype('float32')\n\n# x_train /= 255\n\n\n\n# print('Not using data augmentation.')\n# model.fit(x_train, y_train,\n# batch_size=batch_size,\n# epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# plt.imshow(grid)\n# plt.title('Cubic')\n# plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}